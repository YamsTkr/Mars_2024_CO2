{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb23745-811c-42c6-92c7-0f6c4f1a668b",
   "metadata": {},
   "source": [
    "# <font color='red'>Modelisation :</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955e719-e91b-41f6-ba17-7c9fbbb2af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Pour afficher les graphiques directement dans le notebook\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7cade-71a6-45cf-a033-0feca0d2f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous repartons des données préalablement nettoyées et enregistrées (notebook Preprocessing)\n",
    "df = pd.read_csv('data_cleaned.csv',index_col=[0])\n",
    "df_thermique = pd.read_csv('data_thermique.csv',index_col=[0])\n",
    "df_hybride = pd.read_csv('data_hybride.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e294c-50cd-471a-8d47-d6a9d08598dc",
   "metadata": {},
   "source": [
    "### <font color='blue'> Séparation train & test  des 3 datasets + standardisation: </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ccd79-3e8b-4c2b-87cd-1395d6fef528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scinder les data en X et y : \n",
    "X = df.drop(\"Emission_co2_(g/km)\",axis = 1)\n",
    "y = df[\"Emission_co2_(g/km)\"]\n",
    "\n",
    "y_thermique = df_thermique['Emission_co2_(g/km)']\n",
    "X_thermique = df_thermique.drop('Emission_co2_(g/km)', axis=1)\n",
    "\n",
    "\n",
    "y_hybride = df_hybride['Emission_co2_(g/km)']\n",
    "X_hybride = df_hybride.drop('Emission_co2_(g/km)', axis=1)\n",
    "\n",
    "#scinder les datas en train et test : \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)\n",
    "\n",
    "X_thermique_train, X_thermique_test, y_thermique_train, y_thermique_test = train_test_split(X_thermique, y_thermique, test_size=0.3, random_state=42)\n",
    "\n",
    "X_hybride_train, X_hybride_test, y_hybride_train, y_hybride_test = train_test_split(X_hybride, y_hybride, test_size=0.3, random_state=42)\n",
    "\n",
    "#Standardiser : \n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_thermique_train_scaled = scaler.fit_transform(X_thermique_train)\n",
    "X_thermique_test_scaled = scaler.transform(X_thermique_test)\n",
    "\n",
    "X_hybride_train_scaled = scaler.fit_transform(X_hybride_train)\n",
    "X_hybride_test_scaled = scaler.transform(X_hybride_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b612d-b792-455b-81df-f823ece7d38d",
   "metadata": {},
   "source": [
    "### <font color='blue'> Régression lineaire: </font>\n",
    "\n",
    "Avant de construire un modèle de régression linéaire, il est crucial de vérifier si la variable cible suit une distribution normale, car cela affecte la validité des résultats et l'interprétation des coefficients. L'analyse de la normalité garantit que les hypothèses de la régression linéaire sont satisfaites, renforçant ainsi la fiabilité et la pertinence du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79aa8ef-50eb-4cfe-b46b-5338a44bf869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser la normalité de la variable cible dans la data complète\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(y, kde=True, color=\"skyblue\", edgecolor=\"black\", linewidth=1, bins=30)\n",
    "plt.title('Histogramme de CO2 (g/km) ', fontsize=16)\n",
    "plt.xlabel('Valeurs de la variable cible', fontsize=14)\n",
    "plt.ylabel('Fréquence', fontsize=14)\n",
    "\n",
    "# Enregistrer l'image\n",
    "plt.savefig('histogramme_variable_cible.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ad27c0-d96c-4f60-888b-79fe9146ece5",
   "metadata": {},
   "source": [
    "### <font color='blue'> Analyse data voitures thermiques : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def64b4-db51-4ea0-8388-e3ca8cff61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer un histogramme\n",
    "sns.histplot(df_thermique['Emission_co2_(g/km)'], kde=True, bins=50, edgecolor='black', color='blue', line_kws={'color': 'red', 'linewidth': 2})\n",
    "\n",
    "\n",
    "# Calculer la moyenne et la médiane\n",
    "mean_value = df_thermique['Emission_co2_(g/km)'].mean()\n",
    "median_value = df_thermique['Emission_co2_(g/km)'].median()\n",
    "\n",
    "# Tracer des lignes verticales pour représenter la moyenne et la médiane\n",
    "plt.axvline(mean_value, color='red', linewidth=1, label='Moyenne de distribution')\n",
    "plt.axvline(median_value, color='red', linestyle='dashed', linewidth=1, label='Médiane de distribution')\n",
    "\n",
    "# Ajouter une légende\n",
    "plt.legend()\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a913879-4b72-4ddf-b894-c0108c848fd2",
   "metadata": {},
   "source": [
    "### <font color='blue'> Sans validation croisée : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc66fc7-dcaf-4534-bbc5-93bf919dd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création et entraînement du modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "model.fit(X_thermique_train_scaled, y_thermique_train)\n",
    "\n",
    "# Prédiction des valeurs cibles pour les ensembles d'entraînement et de test\n",
    "y_thermique_train_pred = model.predict(X_thermique_train_scaled)\n",
    "y_thermique_test_pred = model.predict(X_thermique_test_scaled)\n",
    "\n",
    "# Calcul des métriques pour l'entraînement\n",
    "r2_train = r2_score(y_thermique_train, y_thermique_train_pred)\n",
    "mae_train = mean_absolute_error(y_thermique_train, y_thermique_train_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_thermique_train, y_thermique_train_pred))\n",
    "\n",
    "# Calcul des métriques pour le test\n",
    "r2_test = r2_score(y_thermique_test, y_thermique_test_pred)\n",
    "mae_test = mean_absolute_error(y_thermique_test, y_thermique_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_thermique_test, y_thermique_test_pred))\n",
    "\n",
    "print(\"Régression Linéaire sans validation croisée\")\n",
    "print(f\"R² pour l'entraînement : {r2_train}\")\n",
    "print(f\"R² pour le test : {r2_test}\")\n",
    "print(f\"MAE pour l'entraînement : {mae_train}\")\n",
    "print(f\"MAE pour le test : {mae_test}\")\n",
    "print(f\"RMSE pour l'entraînement : {rmse_train}\")\n",
    "print(f\"RMSE pour le test : {rmse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b443d4-a313-408e-a858-d7e7c363d9a3",
   "metadata": {},
   "source": [
    "### <font color='blue'> Avec validation croisée : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a13b20-aaf2-4157-9cce-18135a30b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model, X_thermique_train_scaled, y_thermique_train, cv=10,\n",
    "                            scoring=('r2', 'neg_mean_absolute_error', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True)\n",
    "\n",
    "# Moyennes des scores R², MAE et RMSE pour l'entraînement et le test\n",
    "mean_r2_train = np.mean(cv_results['train_r2'])\n",
    "mean_r2_test = np.mean(cv_results['test_r2'])\n",
    "mean_mae_train = -np.mean(cv_results['train_neg_mean_absolute_error'])\n",
    "mean_mae_test = -np.mean(cv_results['test_neg_mean_absolute_error'])\n",
    "mean_rmse_train = -np.mean(cv_results['train_neg_root_mean_squared_error'])\n",
    "mean_rmse_test = -np.mean(cv_results['test_neg_root_mean_squared_error'])\n",
    "\n",
    "print(\"Régression Linéaire avec validation croisée\")\n",
    "print(f\"R² moyen pour l'entraînement : {mean_r2_train}\")\n",
    "print(f\"R² moyen pour le test : {mean_r2_test}\")\n",
    "print(f\"MAE moyen pour l'entraînement : {mean_mae_train}\")\n",
    "print(f\"MAE moyen pour le test : {mean_mae_test}\")\n",
    "print(f\"RMSE moyen pour l'entraînement : {mean_rmse_train}\")\n",
    "print(f\"RMSE moyen pour le test : {mean_rmse_test}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1d729-73a1-49a0-ae1d-02a89d7d2d76",
   "metadata": {},
   "source": [
    "### <font color='blue'> Analyse des residus : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a545d8-1fe0-4084-8cb3-fdbb125a31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les résidus\n",
    "residuals = y_thermique_test - y_thermique_test_pred\n",
    "\n",
    "# Visualiser les résidus\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribution des résidus')\n",
    "plt.xlabel('Résidus')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.show()\n",
    "# Enregistrer l'image\n",
    "plt.savefig('distribution des lr thermiques.png', bbox_inches='tight')\n",
    "\n",
    "# Vérifier l'homoscédasticité\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_thermique_test_pred, y=residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Résidus par rapport aux valeurs prédites')\n",
    "plt.xlabel('Valeurs prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a213d8f-52f3-4929-8431-0ad1038e0688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les résidus normalisés\n",
    "residuals_standardized = (residuals - residuals.mean()) / residuals.std()\n",
    "\n",
    "# Q-Q plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "stats.probplot(residuals_standardized, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot des Résidus\")\n",
    "plt.xlabel(\"Quantiles théoriques (distribution normale)\")\n",
    "plt.ylabel(\"Quantiles observés\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ae8a05-865a-4ab6-adc9-e59abea8c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer le nuage de points entre les valeurs prédites et les valeurs réelles avec une ligne de corrélation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_thermique_test_pred, y_thermique_test, alpha=0.5)\n",
    "plt.plot([y_thermique_test.min(), y_thermique_test.max()], [y_thermique_test.min(), y_thermique_test.max()], 'r--', lw=2)  # Ajouter une ligne de corrélation parfaite\n",
    "plt.title(\"Nuage de points entre les valeurs prédites et les valeurs réelles (test)\")\n",
    "plt.xlabel(\"Valeurs prédites\")\n",
    "plt.ylabel(\"Valeurs réelles\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c59fce-b66f-4fdd-b20c-61d9e630c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définir le style de Seaborn sur darkgrid\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Créer la boîte à moustaches des résidus avec Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=residuals, orient='h', color='cornflowerblue')\n",
    "plt.title(\"Boîte à moustaches des résidus\")\n",
    "plt.xlabel(\"Résidus\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06790623-63e7-48a9-ad61-c8542900794b",
   "metadata": {},
   "source": [
    "#### <font color='pink'> Elasticnet / Ridge et lasso pour les voitures thermiques : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21182c-a600-4310-900e-d5e7982af7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les modèles\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "ridge = Ridge(alpha=0.1)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Entraîner les modèles\n",
    "elastic_net.fit(X_thermique_train_scaled, y_thermique_train)\n",
    "ridge.fit(X_thermique_train_scaled, y_thermique_train)\n",
    "lasso.fit(X_thermique_train_scaled, y_thermique_train)\n",
    "\n",
    "# Prédire les valeurs cibles pour les ensembles d'entraînement et de test\n",
    "y_train_pred_elastic_net = elastic_net.predict(X_thermique_train_scaled)\n",
    "y_test_pred_elastic_net = elastic_net.predict(X_thermique_test_scaled)\n",
    "\n",
    "y_train_pred_ridge = ridge.predict(X_thermique_train_scaled)\n",
    "y_test_pred_ridge = ridge.predict(X_thermique_test_scaled)\n",
    "\n",
    "y_train_pred_lasso = lasso.predict(X_thermique_train_scaled)\n",
    "y_test_pred_lasso = lasso.predict(X_thermique_test_scaled)\n",
    "\n",
    "# Calculer les scores R² pour l'entraînement et le test\n",
    "r2_train_elastic_net = r2_score(y_thermique_train, y_train_pred_elastic_net)\n",
    "r2_test_elastic_net = r2_score(y_thermique_test, y_test_pred_elastic_net)\n",
    "\n",
    "r2_train_ridge = r2_score(y_thermique_train, y_train_pred_ridge)\n",
    "r2_test_ridge = r2_score(y_thermique_test, y_test_pred_ridge)\n",
    "\n",
    "r2_train_lasso = r2_score(y_thermique_train, y_train_pred_lasso)\n",
    "r2_test_lasso = r2_score(y_thermique_test, y_test_pred_lasso)\n",
    "\n",
    "# Calculer les erreurs (MAE et RMSE) pour l'entraînement et le test\n",
    "mae_train_elastic_net = mean_absolute_error(y_thermique_train, y_train_pred_elastic_net)\n",
    "rmse_train_elastic_net = mean_squared_error(y_thermique_train, y_train_pred_elastic_net, squared=False)\n",
    "mae_test_elastic_net = mean_absolute_error(y_thermique_test, y_test_pred_elastic_net)\n",
    "rmse_test_elastic_net = mean_squared_error(y_thermique_test, y_test_pred_elastic_net, squared=False)\n",
    "\n",
    "mae_train_ridge = mean_absolute_error(y_thermique_train, y_train_pred_ridge)\n",
    "rmse_train_ridge = mean_squared_error(y_thermique_train, y_train_pred_ridge, squared=False)\n",
    "mae_test_ridge = mean_absolute_error(y_thermique_test, y_test_pred_ridge)\n",
    "rmse_test_ridge = mean_squared_error(y_thermique_test, y_test_pred_ridge, squared=False)\n",
    "\n",
    "mae_train_lasso = mean_absolute_error(y_thermique_train, y_train_pred_lasso)\n",
    "rmse_train_lasso = mean_squared_error(y_thermique_train, y_train_pred_lasso, squared=False)\n",
    "mae_test_lasso = mean_absolute_error(y_thermique_test, y_test_pred_lasso)\n",
    "rmse_test_lasso = mean_squared_error(y_thermique_test, y_test_pred_lasso, squared=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"ElasticNet - R² pour l'entraînement:\", r2_train_elastic_net)\n",
    "print(\"ElasticNet - R² pour le test:\", r2_test_elastic_net)\n",
    "print(\"ElasticNet - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_elastic_net)\n",
    "print(\"ElasticNet - Mean Absolute Error (MAE) pour le test:\", mae_test_elastic_net)\n",
    "print(\"ElasticNet - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_elastic_net)\n",
    "print(\"ElasticNet - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_elastic_net)\n",
    "\n",
    "print(\"\\nRidge - R² pour l'entraînement:\", r2_train_ridge)\n",
    "print(\"Ridge - R² pour le test:\", r2_test_ridge)\n",
    "print(\"Ridge - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_ridge)\n",
    "print(\"Ridge - Mean Absolute Error (MAE) pour le test:\", mae_test_ridge)\n",
    "print(\"Ridge - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_ridge)\n",
    "print(\"Ridge - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_ridge)\n",
    "\n",
    "print(\"\\nLasso - R² pour l'entraînement:\", r2_train_lasso)\n",
    "print(\"Lasso - R² pour le test:\", r2_test_lasso)\n",
    "print(\"Lasso - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_lasso)\n",
    "print(\"Lasso - Mean Absolute Error (MAE) pour le test:\", mae_test_lasso)\n",
    "print(\"Lasso - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_lasso)\n",
    "print(\"Lasso - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f44be66-568c-4cbf-b147-25809f5e1d5c",
   "metadata": {},
   "source": [
    "### <font color='blue'> Analyse data voitures hybrides : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5316c2-1d39-4dc0-933f-4374001b496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer un histogramme\n",
    "sns.histplot(df_hybride['Emission_co2_(g/km)'], kde=True, bins=50, edgecolor='black', color='blue', line_kws={'color': 'red', 'linewidth': 2})\n",
    "\n",
    "\n",
    "# Calculer la moyenne et la médiane\n",
    "mean_value = df_hybride['Emission_co2_(g/km)'].mean()\n",
    "median_value = df_hybride['Emission_co2_(g/km)'].median()\n",
    "\n",
    "# Tracer des lignes verticales pour représenter la moyenne et la médiane\n",
    "plt.axvline(mean_value, color='red', linewidth=1, label='Moyenne de distribution')\n",
    "plt.axvline(median_value, color='red', linestyle='dashed', linewidth=1, label='Médiane de distribution')\n",
    "\n",
    "# Ajouter une légende\n",
    "plt.legend()\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2874e-b816-4567-8ea8-3e4a0bcd8629",
   "metadata": {},
   "source": [
    "### <font color='blue'> sans validation croisée : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4292b6-041b-4bfe-a794-0be03cf127ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création et entraînement du modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "model.fit(X_hybride_train_scaled, y_hybride_train)\n",
    "\n",
    "# Prédiction des valeurs cibles pour les ensembles d'entraînement et de test\n",
    "y_hybride_train_pred = model.predict(X_hybride_train_scaled)\n",
    "y_hybride_test_pred = model.predict(X_hybride_test_scaled)\n",
    "\n",
    "# Calcul des métriques pour l'entraînement\n",
    "r2_train = r2_score(y_hybride_train, y_hybride_train_pred)\n",
    "mae_train = mean_absolute_error(y_hybride_train, y_hybride_train_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_hybride_train, y_hybride_train_pred))\n",
    "\n",
    "# Calcul des métriques pour le test\n",
    "r2_test = r2_score(y_hybride_test, y_hybride_test_pred)\n",
    "mae_test = mean_absolute_error(y_hybride_test, y_hybride_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_hybride_test, y_hybride_test_pred))\n",
    "\n",
    "print(\"Régression Linéaire sans validation croisée\")\n",
    "print(f\"R² pour l'entraînement : {r2_train}\")\n",
    "print(f\"R² pour le test : {r2_test}\")\n",
    "print(f\"MAE pour l'entraînement : {mae_train}\")\n",
    "print(f\"MAE pour le test : {mae_test}\")\n",
    "print(f\"RMSE pour l'entraînement : {rmse_train}\")\n",
    "print(f\"RMSE pour le test : {rmse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0715ad0-b579-4a58-908d-b8651e3c6ff9",
   "metadata": {},
   "source": [
    "### <font color='blue'> Avec validation croisée : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daeb150-0d60-4f76-b470-13d5c4498f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée\n",
    "cv_results = cross_validate(model, X_hybride_train_scaled, y_hybride_train, cv=10,\n",
    "                            scoring=('r2', 'neg_mean_absolute_error', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True)\n",
    "\n",
    "# Moyennes des scores R², MAE et RMSE pour l'entraînement et le test\n",
    "mean_r2_train = np.mean(cv_results['train_r2'])\n",
    "mean_r2_test = np.mean(cv_results['test_r2'])\n",
    "mean_mae_train = -np.mean(cv_results['train_neg_mean_absolute_error'])\n",
    "mean_mae_test = -np.mean(cv_results['test_neg_mean_absolute_error'])\n",
    "mean_rmse_train = -np.mean(cv_results['train_neg_root_mean_squared_error'])\n",
    "mean_rmse_test = -np.mean(cv_results['test_neg_root_mean_squared_error'])\n",
    "\n",
    "print(\"Régression Linéaire avec validation croisée\")\n",
    "print(f\"R² moyen pour l'entraînement : {mean_r2_train}\")\n",
    "print(f\"R² moyen pour le test : {mean_r2_test}\")\n",
    "print(f\"MAE moyen pour l'entraînement : {mean_mae_train}\")\n",
    "print(f\"MAE moyen pour le test : {mean_mae_test}\")\n",
    "print(f\"RMSE moyen pour l'entraînement : {mean_rmse_train}\")\n",
    "print(f\"RMSE moyen pour le test : {mean_rmse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ef330-7874-47c4-b7c5-45c93ceb1b38",
   "metadata": {},
   "source": [
    "### <font color='blue'> Analyse des résidus : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a50578-f282-4297-b2d5-46b4681c328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les résidus\n",
    "residuals = y_hybride_test - y_hybride_test_pred\n",
    "\n",
    "# Visualiser les résidus\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribution des résidus')\n",
    "plt.xlabel('Résidus')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.show()\n",
    "# Enregistrer l'image\n",
    "plt.savefig('distribution des lr thermiques.png', bbox_inches='tight')\n",
    "\n",
    "# Vérifier l'homoscédasticité\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_hybride_test_pred, y=residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Résidus par rapport aux valeurs prédites')\n",
    "plt.xlabel('Valeurs prédites')\n",
    "plt.ylabel('Résidus')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451bac3e-42c8-4348-8b80-7dd88c67485f",
   "metadata": {},
   "source": [
    "#### <font color='pink'> Elasticnet / Ridge et lasso pour les voitures hybrides : </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b964b-14ad-412c-9303-5299e749bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les modèles\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "ridge = Ridge(alpha=0.1)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Entraîner les modèles\n",
    "elastic_net.fit(X_hybride_train_scaled, y_hybride_train)\n",
    "ridge.fit(X_hybride_train_scaled, y_hybride_train)\n",
    "lasso.fit(X_hybride_train_scaled, y_hybride_train)\n",
    "\n",
    "# Prédire les valeurs cibles pour les ensembles d'entraînement et de test\n",
    "y_train_pred_elastic_net = elastic_net.predict(X_hybride_train_scaled)\n",
    "y_test_pred_elastic_net = elastic_net.predict(X_hybride_test_scaled)\n",
    "\n",
    "y_train_pred_ridge = ridge.predict(X_hybride_train_scaled)\n",
    "y_test_pred_ridge = ridge.predict(X_hybride_test_scaled)\n",
    "\n",
    "y_train_pred_lasso = lasso.predict(X_hybride_train_scaled)\n",
    "y_test_pred_lasso = lasso.predict(X_hybride_test_scaled)\n",
    "\n",
    "\n",
    "# Calculer les scores R² pour l'entraînement et le test\n",
    "r2_train_elastic_net = r2_score(y_hybride_train, y_train_pred_elastic_net)\n",
    "r2_test_elastic_net = r2_score(y_hybride_test, y_test_pred_elastic_net)\n",
    "\n",
    "r2_train_ridge = r2_score(y_hybride_train, y_train_pred_ridge)\n",
    "r2_test_ridge = r2_score(y_hybride_test, y_test_pred_ridge)\n",
    "\n",
    "r2_train_lasso = r2_score(y_hybride_train, y_train_pred_lasso)\n",
    "r2_test_lasso = r2_score(y_hybride_test, y_test_pred_lasso)\n",
    "\n",
    "# Calculer les erreurs (MAE et RMSE) pour l'entraînement et le test\n",
    "mae_train_elastic_net = mean_absolute_error(y_hybride_train, y_train_pred_elastic_net)\n",
    "rmse_train_elastic_net = mean_squared_error(y_hybride_train, y_train_pred_elastic_net, squared=False)\n",
    "mae_test_elastic_net = mean_absolute_error(y_hybride_test, y_test_pred_elastic_net)\n",
    "rmse_test_elastic_net = mean_squared_error(y_hybride_test, y_test_pred_elastic_net, squared=False)\n",
    "\n",
    "mae_train_ridge = mean_absolute_error(y_hybride_train, y_train_pred_ridge)\n",
    "rmse_train_ridge = mean_squared_error(y_hybride_train, y_train_pred_ridge, squared=False)\n",
    "mae_test_ridge = mean_absolute_error(y_hybride_test, y_test_pred_ridge)\n",
    "rmse_test_ridge = mean_squared_error(y_hybride_test, y_test_pred_ridge, squared=False)\n",
    "\n",
    "mae_train_lasso = mean_absolute_error(y_hybride_train, y_train_pred_lasso)\n",
    "rmse_train_lasso = mean_squared_error(y_hybride_train, y_train_pred_lasso, squared=False)\n",
    "mae_test_lasso = mean_absolute_error(y_hybride_test, y_test_pred_lasso)\n",
    "rmse_test_lasso = mean_squared_error(y_hybride_test, y_test_pred_lasso, squared=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"ElasticNet - R² pour l'entraînement:\", r2_train_elastic_net)\n",
    "print(\"ElasticNet - R² pour le test:\", r2_test_elastic_net)\n",
    "print(\"ElasticNet - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_elastic_net)\n",
    "print(\"ElasticNet - Mean Absolute Error (MAE) pour le test:\", mae_test_elastic_net)\n",
    "print(\"ElasticNet - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_elastic_net)\n",
    "print(\"ElasticNet - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_elastic_net)\n",
    "\n",
    "print(\"\\nRidge - R² pour l'entraînement:\", r2_train_ridge)\n",
    "print(\"Ridge - R² pour le test:\", r2_test_ridge)\n",
    "print(\"Ridge - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_ridge)\n",
    "print(\"Ridge - Mean Absolute Error (MAE) pour le test:\", mae_test_ridge)\n",
    "print(\"Ridge - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_ridge)\n",
    "print(\"Ridge - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_ridge)\n",
    "\n",
    "print(\"\\nLasso - R² pour l'entraînement:\", r2_train_lasso)\n",
    "print(\"Lasso - R² pour le test:\", r2_test_lasso)\n",
    "print(\"Lasso - Mean Absolute Error (MAE) pour l'entraînement:\", mae_train_lasso)\n",
    "print(\"Lasso - Mean Absolute Error (MAE) pour le test:\", mae_test_lasso)\n",
    "print(\"Lasso - Root Mean Squared Error (RMSE) pour l'entraînement:\", rmse_train_lasso)\n",
    "print(\"Lasso - Root Mean Squared Error (RMSE) pour le test:\", rmse_test_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ea5d1",
   "metadata": {},
   "source": [
    "SGD Regresor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor()\n",
    "sgd.fit(X_train,y_train)\n",
    "print(\"R2 train\",sgd.score(X_train,y_train))\n",
    "print(\"R2 test\",sgd.score(X_test,y_test))\n",
    "y_pred_sgd = sgd.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"rmse\",np.sqrt(mean_squared_error(y_test, y_pred_sgd)))\n",
    "print(\"mae\", mean_absolute_error(y_test, y_pred_sgd))\n",
    "\n",
    "sorted_y_test = np.sort(y_test)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_sgd)\n",
    "plt.plot(sorted_y_test, sorted_y_test, color='red', linestyle='--') \n",
    "plt.xlabel(\"Valeurs réelles\")\n",
    "plt.ylabel(\"Prédictions\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55afff",
   "metadata": {},
   "source": [
    "AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostRegressor(n_estimators=100)\n",
    "ada.fit(X_train,y_train)\n",
    "print(\"R2 train\",ada.score(X_train,y_train))\n",
    "print(\"R2 test\",ada.score(X_test,y_test))\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"rmse\",np.sqrt(mean_squared_error(y_test, y_pred_ada)))\n",
    "print(\"mae\", mean_absolute_error(y_test, y_pred_ada))\n",
    "\n",
    "sorted_y_test = np.sort(y_test)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_ada)\n",
    "plt.plot(sorted_y_test, sorted_y_test, color='red', linestyle='--') \n",
    "plt.xlabel(\"Valeurs réelles\")\n",
    "plt.ylabel(\"Prédictions\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39792107",
   "metadata": {},
   "source": [
    "GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7798a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=42)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred_gbr = gbr.predict(X_test)\n",
    "display(gbr.score(X_test, y_test))\n",
    "display(gbr.score(X_train, y_train))\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae_gbr = mean_absolute_error(y_test, y_pred_gbr)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) - vous l'avez déjà fait\n",
    "mse_gbr = mean_squared_error(y_test, y_pred_gbr)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse_gbr = mean_squared_error(y_test, y_pred_gbr, squared=False)\n",
    "\n",
    "# Calculate R-squared for test set\n",
    "r2_gbr_test = r2_score(y_test, y_pred_gbr)\n",
    "\n",
    "# Pour le jeu d'entraînement, vous devez d'abord prédire les valeurs pour X_train\n",
    "y_pred_gbr_train = gbr.predict(X_train)\n",
    "\n",
    "# Calculate R-squared for train set\n",
    "r2_gbr_train = r2_score(y_train, y_pred_gbr_train)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"MAE: {mae_gbr}\")\n",
    "print(f\"MSE: {mse_gbr}\")\n",
    "print(f\"RMSE: {rmse_gbr}\")\n",
    "print(f\"R-squared train: {r2_gbr_train}\")\n",
    "print(f\"R-squared test: {r2_gbr_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46419a12",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle XG Boost sur données ICE + hyb\n",
    "\n",
    "\n",
    "# Instancier le modèle XGBoostRegressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Entraîner le modèle\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Calculer l'erreur quadratique moyenne (MSE) sur l'ensemble de test\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "              \n",
    "R2_train = xgb_model.score(X_train,y_train)\n",
    "R2_test  = xgb_model.score(X_test,y_test)\n",
    "\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "print(\"Mean Absolute Error (MAE) :\", mae)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Train:\", R2_train)\n",
    "print(\"R-squared Test:\", R2_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tri des valeurs de y_test pour tracer la droite y_pred = y_test\n",
    "sorted_y_test = np.sort(y_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "#sns.scatterplot(x=yICE_test, y=yICE_pred,color='g')\n",
    "\n",
    "plt.plot(sorted_y_test, sorted_y_test, color='red', linestyle='--')  # Droite y_pred = y_test\n",
    "plt.xlabel(\"Valeurs réelles\")\n",
    "plt.ylabel(\"Prédictions\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# interpretation du modèle\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c1efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle XG Boost sur données ICE  \n",
    "\n",
    "\n",
    "# Instancier le modèle XGBoostRegressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Entraîner le modèle\n",
    "xgb_model.fit(X_thermique_train_scaled, y_thermique_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "yICE_pred = xgb_model.predict(X_thermique_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "# Calculer l'erreur quadratique moyenne (MSE) sur l'ensemble de test\n",
    "mse = mean_squared_error(y_thermique_test, yICE_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "              \n",
    "R2_train = xgb_model.score(X_thermique_train_scaled,y_thermique_train)\n",
    "R2_test  = xgb_model.score(X_thermique_test_scaled,y_thermique_test)\n",
    "\n",
    "mae = np.mean(np.abs(y_thermique_test - yICE_pred))\n",
    "print(\"Mean Absolute Error (MAE) :\", mae)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared Train:\", R2_train)\n",
    "print(\"R-squared Test:\", R2_test)\n",
    "\n",
    "\n",
    "\n",
    "# Tri des valeurs de y_test pour tracer la droite y_pred = y_test\n",
    "sorted_yICE_test = np.sort(y_thermique_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_thermique_test, y=yICE_pred)\n",
    "#sns.scatterplot(x=yICE_test, y=yICE_pred,color='g')\n",
    "\n",
    "plt.plot(sorted_yICE_test, sorted_yICE_test, color='red', linestyle='--')  # Droite y_pred = y_test\n",
    "plt.xlabel(\"Valeurs réelles\")\n",
    "plt.ylabel(\"Prédictions\")\n",
    "plt.show()\n",
    "\n",
    "# interpretation du modèle\n",
    "\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_thermique_test_scaled)\n",
    "shap.summary_plot(shap_values, X_thermique_test_scaled)\n",
    "shap.summary_plot(shap_values, X_thermique_test_scaled, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bf4f1",
   "metadata": {},
   "source": [
    "DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc02264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset complet \n",
    "\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_t_pred = tree.predict(X_train)\n",
    "y_t_pred = tree.predict(X_test)\n",
    "tree_train = tree.score(X_train, y_train)\n",
    "tree_test = tree.score(X_test, y_test)\n",
    "\n",
    "print(\"score train\",tree_train)\n",
    "print(\"score test\", tree_test)\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_t_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_t_pred)\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_t_pred, squared=False)\n",
    "\n",
    "print(\"mae:\", mae_test)\n",
    "print(\"mse:\",mse_test)\n",
    "print(\"rmse:\",rmse_test)\n",
    "\n",
    "#Représentation graphique des valeurs prédites par rapport aux valeurs réelles \n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(x=y_test, y=y_t_pred, color='blue', label='Valeurs Prédites')\n",
    "\n",
    "# Ajout d'une ligne d'identité\n",
    "identity_line = np.linspace(min(y_test), max(y_test), 100)\n",
    "plt.plot(identity_line, identity_line, '--', color='red', label='Ligne d\\'Identité')\n",
    "\n",
    "# Ajouter des étiquettes et une légende\n",
    "plt.xlabel('Valeurs Réelles (y_test)')\n",
    "plt.ylabel('Valeurs Prédites (y_pred)')\n",
    "plt.title('Nuage de points: y_test vs y_pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e19c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir l'importance des features\n",
    "importance = tree.feature_importances_\n",
    "\n",
    "# Créer un dataframe avec les noms des features et leur importance\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importance})\n",
    "\n",
    "# Trier le dataframe par importance décroissante\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Afficher les 10 features les plus importantes\n",
    "print(feature_importance_df.head(10))\n",
    "\n",
    "# Afficher l'importance des features sous forme de graphique à barres\n",
    "plt.bar(range(len(feature_importance_df)), feature_importance_df['Importance'], align='center')\n",
    "plt.xticks(range(len(feature_importance_df)), feature_importance_df['Feature'], rotation=90)\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8021cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbres de décision pour df_thermique\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "tree.fit(X_thermique_train_scaled, y_thermique_train)\n",
    "\n",
    "\n",
    "y_thermique_t_pred = tree.predict(X_thermique_test_scaled)\n",
    "tree_train2 = tree.score(X_thermique_train_scaled, y_thermique_train)\n",
    "tree_test2 = tree.score(X_thermique_test_scaled, y_thermique_test)\n",
    "\n",
    "print(\"score train:\",tree_train2)\n",
    "print(\"score test:\",tree_test2)\n",
    "\n",
    "mae_test_t = mean_absolute_error(y_thermique_test, y_thermique_t_pred)\n",
    "\n",
    "mse_test_t = mean_squared_error(y_thermique_test, y_thermique_t_pred)\n",
    "\n",
    "rmse_test_t = mean_squared_error(y_thermique_test, y_thermique_t_pred, squared=False)\n",
    "\n",
    "print(\"mae:\", mae_test_t)\n",
    "print(\"mse:\", mse_test_t)\n",
    "print(\"rmse:\", rmse_test_t)\n",
    "\n",
    "#Représentation graphique valeurs prédite vs valeurs réelles\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(x=y_thermique_test, y=y_thermique_t_pred, color='blue', label='Valeurs Prédites')\n",
    "\n",
    "# Ajout d'une ligne d'identité\n",
    "identity_line = np.linspace(min(y_thermique_test), max(y_thermique_test), 100)\n",
    "plt.plot(identity_line, identity_line, '--', color='red', label='Ligne d\\'Identité')\n",
    "\n",
    "# Ajouter des étiquettes et une légende\n",
    "plt.xlabel('Valeurs Réelles (y_thermique_test)')\n",
    "plt.ylabel('Valeurs Prédites (y_thermique_pred)')\n",
    "plt.title('Nuage de points: y_test vs y_pred voitures thermiques')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir l'importance des features\n",
    "importance = tree.feature_importances_\n",
    "\n",
    "# Créer un dataframe avec les noms des features et leur importance\n",
    "feature_importance_df_t = pd.DataFrame({'Feature': X_thermique.columns, 'Importance': importance})\n",
    "\n",
    "# Trier le dataframe par importance décroissante\n",
    "feature_importance_df_t = feature_importance_df_t.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Afficher les 10 features les plus importantes\n",
    "print(feature_importance_df_t.head(10))\n",
    "\n",
    "# Afficher l'importance des features sous forme de graphique à barres\n",
    "plt.bar(range(len(feature_importance_df_t)), feature_importance_df_t['Importance'], align='center')\n",
    "plt.xticks(range(len(feature_importance_df_t)), feature_importance_df_t['Feature'], rotation=90)\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance sans les hybrides')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ce9f7",
   "metadata": {},
   "source": [
    "RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Random_forest   sur thermique + Hybrides\n",
    "\n",
    "\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "rf_model.fit(X_train, y_train)\n",
    "importances =rf_model.feature_importances_\n",
    "# Afficher les importances des variables\n",
    "for i, importance in enumerate(importances):\n",
    "    print(f\"Variable {i}: Importance = {importance}\")\n",
    "\n",
    "# Faites des prédictions sur l'ensemble de test\n",
    "y_pred = rf_model.predict(X_test)\n",
    "ICE_hyb_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "R2_train = rf_model.score(X_train,y_train)\n",
    "R2_test  = rf_model.score(X_test,y_test)\n",
    "\n",
    "print('taille de X_test',X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "rmse = np.sqrt(ICE_hyb_mse)\n",
    "\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "print(\"Mean Absolute Error (MAE) :\", mae)\n",
    "print(\"Mean Squared Error:\", ICE_hyb_mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared train:\", R2_train)\n",
    "print(\"R-squared test:\", R2_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5a6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Random_forest sur thermique uniquement\n",
    "\n",
    "rf_model_ICE = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "rf_model_ICE.fit(X_thermique_train, y_thermique_train)\n",
    "Importance_Thermique =rf_model_ICE.feature_importances_\n",
    "\n",
    "# Afficher les importances des variables\n",
    "for i, importance in enumerate(Importance_Thermique):\n",
    "    print(f\"Variable {i}: Importance_Thermique = {importance}\")\n",
    "\n",
    "# Faites des prédictions sur l'ensemble de test\n",
    "yICE_pred = rf_model_ICE.predict(X_thermique_test_scaled)\n",
    "ICE_mse = mean_squared_error(y_thermique_test, yICE_pred)\n",
    "\n",
    " \n",
    "R2_train_ICE = rf_model_ICE.score(X_thermique_train,y_thermique_train)\n",
    "R2_test_ICE = rf_model_ICE.score(X_thermique_test,y_thermique_test)\n",
    "\n",
    "print('taille de X_thermique_test',X_thermique_test_scaled.shape)\n",
    "\n",
    "\n",
    "\n",
    "rmse = np.sqrt(ICE_mse)\n",
    "\n",
    "mae = np.mean(np.abs(y_thermique_test - yICE_pred))\n",
    "print(\"Mean Absolute Error (MAE) :\", mae)\n",
    "print(\"Mean Squared Error:\", ICE_mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared train:\", R2_train_ICE)\n",
    "print(\"R-squared test:\", R2_test_ICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6add0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un graphique à barres pour visualiser les importances des variables\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(range(len(importances)), importances, tick_label=X_train.columns,label='thermique+Hyb',color='blue')\n",
    "\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Importances des variables du modèle RandomForest thermique+Hyb')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Créer un graphique à barres pour visualiser les importances des variables\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(range(len(Importance_Thermique)), Importance_Thermique, tick_label=X_thermique_train_scaled.columns,label='thermique',color='green')\n",
    "\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Importances des variables du modèle RandomForest thermique')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a117d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tri des valeurs de y_test pour tracer la droite y_pred = y_test\n",
    "sorted_y_test = np.sort(y_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred,label='ICE+Hyb',color='b')\n",
    "sns.scatterplot(x=y_thermique_test, y=yICE_pred,label='ICE',color='g')\n",
    "\n",
    "plt.plot(sorted_y_test, sorted_y_test,color='red', linestyle='--')  # Droite y_pred = y_test\n",
    "plt.xlabel(\"Valeurs réelles\")\n",
    "plt.ylabel(\"Prédictions\")\n",
    "plt.legend()\n",
    "plt.title('Comparaison des prédictions du modèle RandomForest entre datasets thermique et thermique+Hyb ')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
